# AI Discovery Configuration

# LLM Provider (anthropic or ollama)
llm.provider=anthropic

# Anthropic settings
anthropic.api.key=${ANTHROPIC_API_KEY:}
anthropic.model=claude-sonnet-4-20250514
anthropic.max-tokens=4096

# Ollama settings
ollama.base-url=http://localhost:11434
ollama.model=qwen3:14b
ollama.timeout=PT5M

# Temperature for research/analysis
llm.temperature.research=0.3

# Universe storage (shared with aipublisher)
discovery.storage-directory=${user.home}/.aipublisher/universes

# Spring Boot
spring.main.banner-mode=off
spring.main.lazy-initialization=true

# Logging
logging.level.root=WARN
logging.level.com.jakefear.aidiscovery=INFO
logging.level.dev.langchain4j=WARN
